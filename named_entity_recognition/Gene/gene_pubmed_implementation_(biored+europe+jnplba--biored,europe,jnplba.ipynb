{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c715b838-828b-4c7a-9701-259135003070",
     "showTitle": true,
     "title": "Importing libraries"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import time\n",
    "import datetime\n",
    "# import keras\n",
    "import nltk\n",
    "from nltk.tokenize.util import align_tokens\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "nltk.download('punkt')\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset,Dataset ,DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dff9cf1-3c07-41c3-8212-0b97b7bd8d40",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d3f4aff-1839-4fbf-9752-dd22bbe73d8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2170b1a-e3aa-4b7b-802e-6e8c7af8c58f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#create dataframe from data\n",
    "def read_file(path):\n",
    "  data=open(path, \"r\")\n",
    "  data=json.load(data)\n",
    "  # print(data)\n",
    "  string_labels = []\n",
    "  for item in data:\n",
    "    text = item['Text']\n",
    "    id= item['id']\n",
    "    sentences_split = nltk.word_tokenize(item[\"Text\"])\n",
    "    # print(sentences_split)\n",
    "    try:\n",
    "        token_spans = align_tokens(sentences_split,text)\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "        # print(token_spans)\n",
    "    for i in range(len(token_spans)):\n",
    "        token_in_annotation = False\n",
    "        for annotation in item['annotation']:\n",
    "            if int(annotation[\"start\"])<= token_spans[i][0] and int(annotation['end'])>=token_spans[i][1]:\n",
    "                string_labels.append((text[token_spans[i][0]:token_spans[i][1]],annotation['type']))\n",
    "                token_in_annotation = True\n",
    "        if(token_in_annotation==False):\n",
    "            string_labels.append((text[token_spans[i][0]:token_spans[i][1]],'O'))\n",
    "  df = pd.DataFrame(string_labels, columns =['token', 'label'])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f69da65-5618-4d3f-8565-067668d41cb1",
     "showTitle": true,
     "title": "Read the data (train_data)"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\n"
     ]
    }
   ],
   "source": [
    "path=\"/dbfs/FileStore/Chanchal/Data_json/gene_protein.json\"\n",
    "train_df=read_file(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6cb49e4-baf2-4fde-8bd3-3443d8798de8",
     "showTitle": true,
     "title": "read(test_data)(biored)"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path=\"/dbfs/FileStore/Chanchal/Data_json/biored.json\"\n",
    "test_df=read_file(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4dbc75d-9e54-4a3f-ade1-6bc774b00fa2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags: 2\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "O               932164\n",
       "Gene_protein    126717\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_labels = ['GP', 'GeneOrGeneProduct', 'protein','O']\n",
    "train_df = train_df[train_df['label'].isin(target_labels)]\n",
    "train_df['label'] = train_df['label'].replace(['GP','GeneOrGeneProduct', 'protein'], 'Gene_protein')\n",
    "print(\"Number of tags: {}\".format(len(train_df.label.unique())))\n",
    "frequencies = train_df.label.value_counts()\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "692950cd-a613-40b8-a865-802a3153a9c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags: 2\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "O                    141466\n",
       "GeneOrGeneProduct      8168\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_df = test_df[test_df['label'].isin(target_labels)]\n",
    "print(\"Number of tags: {}\".format(len(test_df.label.unique())))\n",
    "frequencies = test_df.label.value_counts()\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "671b7522-20c6-45fe-b755-3607cf4fadca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Aggregating tokens into a sentence to be used as input for training data\n",
    "def aggr(df):\n",
    "  df['group']=(df['token'] == '.').cumsum()\n",
    "  new_df = df.groupby('group').agg({'token': ' '.join, 'label': ' '.join}).reset_index(drop=True)\n",
    "  new_df.rename(columns = {'token':'text', 'label':'labels'}, inplace = True)\n",
    "  return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "158a1b1b-6c2f-4135-ac39-b8362a9f2648",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_n_df=aggr(train_df)\n",
    "test_n_df=aggr(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e773e024-8d0f-442a-8803-5ae8492e784d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split labels based on whitespace and turn them into a list\n",
    "labels = [i.split() for i in train_n_df['labels'].values.tolist()]\n",
    "\n",
    "# Check how many labels are there in the dataset\n",
    "unique_labels = set()\n",
    "\n",
    "for lb in labels:\n",
    "  [unique_labels.add(i) for i in lb if i not in unique_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66c6d673-c468-4600-b937-a34c7ae18a60",
     "showTitle": true,
     "title": "Mapping label to ids"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Gene_protein': 0, 'O': 1}\n"
     ]
    }
   ],
   "source": [
    "# Map each label into its id representation and vice versa\n",
    "labels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\n",
    "ids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}\n",
    "print(labels_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ecac7cc-6f37-45fa-80f5-c1327c63e4fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "354fd744-9678-4332-8a60-af95b20056ce",
     "showTitle": true,
     "title": "Implementing model"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "MAX_LEN = 512\n",
    "batch_size=16\n",
    "epochs = 3\n",
    "lr = 2e-04\n",
    "MAX_GRAD_NORM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ce3dec2-08a2-452b-b2df-abd5f3a07d71",
     "showTitle": true,
     "title": "Tokenizing the texts(train_data)"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenizing the input\n",
    "def tokenizing(text):\n",
    "  txt=text.values.tolist()\n",
    "  text_tokenized = tokenizer(txt, padding='max_length', max_length=MAX_LEN , truncation=True, return_tensors=\"pt\")\n",
    "  input_ids=text_tokenized['input_ids']\n",
    "  attention_masks=text_tokenized['attention_mask']\n",
    "  return input_ids,attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3c1c820-598c-472c-993f-eb4ed7d6b434",
     "showTitle": true,
     "title": "Balancing the labels according to the tokenized text(training set)"
    }
   },
   "outputs": [],
   "source": [
    "#Balancing the labels according to the tokens\n",
    "def align_label(texts, labels):\n",
    "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=MAX_LEN , truncation=True)\n",
    "    label_all_tokens=True\n",
    "\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "\n",
    "    for word_idx in word_ids:\n",
    "\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "\n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(labels_to_ids[labels[word_idx]])\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "            try:\n",
    "                label_ids.append(labels_to_ids[labels[word_idx]] if label_all_tokens else -100)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "\n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3611de41-f574-4941-a379-f199dfc1b66b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#converting text and labels for train_data\n",
    "\n",
    "lb = [i.split() for i in train_n_df['labels'].values.tolist()]\n",
    "txt = train_n_df['text'].values.tolist()\n",
    "train_new_label=[align_label(i,j) for i,j in zip(txt, lb)]\n",
    "train_input_ids,train_attention_masks=tokenizing(train_n_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f9aaed7-aeee-40b7-a3fb-5788408bd03e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#converting text and labels for test_data\n",
    "\n",
    "lb = [i.split() for i in test_n_df['labels'].values.tolist()]\n",
    "txt = test_n_df['text'].values.tolist()\n",
    "test_new_label=[align_label(i,j) for i,j in zip(txt, lb)]\n",
    "test_input_ids,test_attention_masks=tokenizing(test_n_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0be574b6-558b-492c-92e0-d4123e52e898",
     "showTitle": true,
     "title": "Converting inputs for bert in the form of Tensors(train)"
    }
   },
   "outputs": [],
   "source": [
    "train_pt_input_ids = torch.stack(list(train_input_ids), dim=0)\n",
    "\n",
    "train_pt_attention_masks = torch.stack(list(train_attention_masks), dim=0)\n",
    "\n",
    "train_pt_labels = torch.tensor(train_new_label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aec4ba09-33b1-49ea-b36a-887d251b0cda",
     "showTitle": true,
     "title": "Converting inputs for bert in the form of Tensors(test)"
    }
   },
   "outputs": [],
   "source": [
    "test_pt_input_ids = torch.stack(list(test_input_ids), dim=0)\n",
    "\n",
    "test_pt_attention_masks = torch.stack(list(test_attention_masks), dim=0)\n",
    "\n",
    "test_pt_labels = torch.tensor(test_new_label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5355644e-4543-465d-b674-c228660d2f36",
     "showTitle": true,
     "title": "Splitting data into train, val and test dataset"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34,736 training samples\n8,684 validation samples\n6,369 testing samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "import random\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "train_dataset = TensorDataset(train_pt_input_ids, train_pt_attention_masks, train_pt_labels)\n",
    "test_dataset= TensorDataset(test_pt_input_ids, test_pt_attention_masks, test_pt_labels)\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "test_size=len(test_dataset)\n",
    "train_dataset, valid_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))\n",
    "print('{:>5,} testing samples'.format(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "221fbaf8-cf81-4815-bad7-e84f7b122190",
     "showTitle": true,
     "title": "Converting dataset in the form of Data loader"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = batch_size )\n",
    "\n",
    "validation_dataloader = DataLoader(valid_dataset, sampler = SequentialSampler(valid_dataset), batch_size = batch_size)\n",
    "\n",
    "test_dataloader=DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = batch_size )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a259d498-7146-4586-8a81-ac604a70bc41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "from transformers import BertForTokenClassification, AdamW, BertConfig\n",
    "\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",num_labels=len(labels_to_ids))\n",
    "# model = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(labels_to_ids))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4f93c23-642e-4263-abed-9cd894a776aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# defining the optimizer\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr)\n",
    "\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01e8dd80-281b-4dbb-8afa-81ff3eee7386",
     "showTitle": true,
     "title": "Training the model"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 3 ========\nTraining...\n  Batch    40  of  2,171.    Elapsed: 0:00:55.\n  Batch    80  of  2,171.    Elapsed: 0:01:50.\n  Batch   120  of  2,171.    Elapsed: 0:02:47.\n  Batch   160  of  2,171.    Elapsed: 0:03:46.\n  Batch   200  of  2,171.    Elapsed: 0:04:44.\n  Batch   240  of  2,171.    Elapsed: 0:05:41.\n  Batch   280  of  2,171.    Elapsed: 0:06:39.\n  Batch   320  of  2,171.    Elapsed: 0:07:36.\n  Batch   360  of  2,171.    Elapsed: 0:08:34.\n  Batch   400  of  2,171.    Elapsed: 0:09:32.\n  Batch   440  of  2,171.    Elapsed: 0:10:30.\n  Batch   480  of  2,171.    Elapsed: 0:11:28.\n  Batch   520  of  2,171.    Elapsed: 0:12:22.\n  Batch   560  of  2,171.    Elapsed: 0:13:14.\n  Batch   600  of  2,171.    Elapsed: 0:14:07.\n  Batch   640  of  2,171.    Elapsed: 0:15:02.\n  Batch   680  of  2,171.    Elapsed: 0:15:58.\n  Batch   720  of  2,171.    Elapsed: 0:16:56.\n  Batch   760  of  2,171.    Elapsed: 0:17:54.\n  Batch   800  of  2,171.    Elapsed: 0:18:49.\n  Batch   840  of  2,171.    Elapsed: 0:19:42.\n  Batch   880  of  2,171.    Elapsed: 0:20:35.\n  Batch   920  of  2,171.    Elapsed: 0:21:29.\n  Batch   960  of  2,171.    Elapsed: 0:22:24.\n  Batch 1,000  of  2,171.    Elapsed: 0:23:22.\n  Batch 1,040  of  2,171.    Elapsed: 0:24:20.\n  Batch 1,080  of  2,171.    Elapsed: 0:25:18.\n  Batch 1,120  of  2,171.    Elapsed: 0:26:16.\n  Batch 1,160  of  2,171.    Elapsed: 0:27:14.\n  Batch 1,200  of  2,171.    Elapsed: 0:28:12.\n  Batch 1,240  of  2,171.    Elapsed: 0:29:10.\n  Batch 1,280  of  2,171.    Elapsed: 0:30:08.\n  Batch 1,320  of  2,171.    Elapsed: 0:31:05.\n  Batch 1,360  of  2,171.    Elapsed: 0:32:02.\n  Batch 1,400  of  2,171.    Elapsed: 0:33:00.\n  Batch 1,440  of  2,171.    Elapsed: 0:33:57.\n  Batch 1,480  of  2,171.    Elapsed: 0:34:54.\n  Batch 1,520  of  2,171.    Elapsed: 0:35:52.\n  Batch 1,560  of  2,171.    Elapsed: 0:36:48.\n  Batch 1,600  of  2,171.    Elapsed: 0:37:41.\n  Batch 1,640  of  2,171.    Elapsed: 0:38:33.\n  Batch 1,680  of  2,171.    Elapsed: 0:39:27.\n  Batch 1,720  of  2,171.    Elapsed: 0:40:22.\n  Batch 1,760  of  2,171.    Elapsed: 0:41:14.\n  Batch 1,800  of  2,171.    Elapsed: 0:42:07.\n  Batch 1,840  of  2,171.    Elapsed: 0:43:00.\n  Batch 1,880  of  2,171.    Elapsed: 0:43:54.\n  Batch 1,920  of  2,171.    Elapsed: 0:44:50.\n  Batch 1,960  of  2,171.    Elapsed: 0:45:48.\n  Batch 2,000  of  2,171.    Elapsed: 0:46:47.\n  Batch 2,040  of  2,171.    Elapsed: 0:47:45.\n  Batch 2,080  of  2,171.    Elapsed: 0:48:43.\n  Batch 2,120  of  2,171.    Elapsed: 0:49:41.\n  Batch 2,160  of  2,171.    Elapsed: 0:50:39.\n\n  Average training loss: 0.14\n  Training epcoh took: 0:50:56\nRunning Validation...\n  Average validation loss: 0.10\n======== Epoch 2 / 3 ========\nTraining...\n  Batch    40  of  2,171.    Elapsed: 0:00:54.\n  Batch    80  of  2,171.    Elapsed: 0:01:50.\n  Batch   120  of  2,171.    Elapsed: 0:02:49.\n  Batch   160  of  2,171.    Elapsed: 0:03:46.\n  Batch   200  of  2,171.    Elapsed: 0:04:44.\n  Batch   240  of  2,171.    Elapsed: 0:05:42.\n  Batch   280  of  2,171.    Elapsed: 0:06:39.\n  Batch   320  of  2,171.    Elapsed: 0:07:38.\n  Batch   360  of  2,171.    Elapsed: 0:08:33.\n  Batch   400  of  2,171.    Elapsed: 0:09:26.\n  Batch   440  of  2,171.    Elapsed: 0:10:19.\n  Batch   480  of  2,171.    Elapsed: 0:11:13.\n  Batch   520  of  2,171.    Elapsed: 0:12:08.\n  Batch   560  of  2,171.    Elapsed: 0:13:06.\n  Batch   600  of  2,171.    Elapsed: 0:14:04.\n  Batch   640  of  2,171.    Elapsed: 0:15:03.\n  Batch   680  of  2,171.    Elapsed: 0:16:01.\n  Batch   720  of  2,171.    Elapsed: 0:16:59.\n  Batch   760  of  2,171.    Elapsed: 0:17:58.\n  Batch   800  of  2,171.    Elapsed: 0:18:56.\n  Batch   840  of  2,171.    Elapsed: 0:19:54.\n  Batch   880  of  2,171.    Elapsed: 0:20:53.\n  Batch   920  of  2,171.    Elapsed: 0:21:51.\n  Batch   960  of  2,171.    Elapsed: 0:22:50.\n  Batch 1,000  of  2,171.    Elapsed: 0:23:48.\n  Batch 1,040  of  2,171.    Elapsed: 0:24:47.\n  Batch 1,080  of  2,171.    Elapsed: 0:25:45.\n  Batch 1,120  of  2,171.    Elapsed: 0:26:41.\n  Batch 1,160  of  2,171.    Elapsed: 0:27:34.\n  Batch 1,200  of  2,171.    Elapsed: 0:28:27.\n  Batch 1,240  of  2,171.    Elapsed: 0:29:20.\n  Batch 1,280  of  2,171.    Elapsed: 0:30:15.\n  Batch 1,320  of  2,171.    Elapsed: 0:31:12.\n  Batch 1,360  of  2,171.    Elapsed: 0:32:11.\n  Batch 1,400  of  2,171.    Elapsed: 0:33:09.\n  Batch 1,440  of  2,171.    Elapsed: 0:34:07.\n  Batch 1,480  of  2,171.    Elapsed: 0:35:04.\n  Batch 1,520  of  2,171.    Elapsed: 0:35:58.\n  Batch 1,560  of  2,171.    Elapsed: 0:36:51.\n  Batch 1,600  of  2,171.    Elapsed: 0:37:44.\n  Batch 1,640  of  2,171.    Elapsed: 0:38:38.\n  Batch 1,680  of  2,171.    Elapsed: 0:39:34.\n  Batch 1,720  of  2,171.    Elapsed: 0:40:32.\n  Batch 1,760  of  2,171.    Elapsed: 0:41:26.\n  Batch 1,800  of  2,171.    Elapsed: 0:42:19.\n  Batch 1,840  of  2,171.    Elapsed: 0:43:12.\n  Batch 1,880  of  2,171.    Elapsed: 0:44:06.\n  Batch 1,920  of  2,171.    Elapsed: 0:45:01.\n  Batch 1,960  of  2,171.    Elapsed: 0:45:59.\n  Batch 2,000  of  2,171.    Elapsed: 0:46:58.\n  Batch 2,040  of  2,171.    Elapsed: 0:47:55.\n  Batch 2,080  of  2,171.    Elapsed: 0:48:52.\n  Batch 2,120  of  2,171.    Elapsed: 0:49:50.\n  Batch 2,160  of  2,171.    Elapsed: 0:50:47.\n\n  Average training loss: 0.08\n  Training epcoh took: 0:51:03\nRunning Validation...\n  Average validation loss: 0.08\n======== Epoch 3 / 3 ========\nTraining...\n  Batch    40  of  2,171.    Elapsed: 0:00:58.\n  Batch    80  of  2,171.    Elapsed: 0:01:56.\n  Batch   120  of  2,171.    Elapsed: 0:02:54.\n  Batch   160  of  2,171.    Elapsed: 0:03:51.\n  Batch   200  of  2,171.    Elapsed: 0:04:49.\n  Batch   240  of  2,171.    Elapsed: 0:05:43.\n  Batch   280  of  2,171.    Elapsed: 0:06:36.\n  Batch   320  of  2,171.    Elapsed: 0:07:29.\n  Batch   360  of  2,171.    Elapsed: 0:08:23.\n  Batch   400  of  2,171.    Elapsed: 0:09:18.\n  Batch   440  of  2,171.    Elapsed: 0:10:15.\n  Batch   480  of  2,171.    Elapsed: 0:11:13.\n  Batch   520  of  2,171.    Elapsed: 0:12:11.\n  Batch   560  of  2,171.    Elapsed: 0:13:09.\n  Batch   600  of  2,171.    Elapsed: 0:14:07.\n  Batch   640  of  2,171.    Elapsed: 0:15:04.\n  Batch   680  of  2,171.    Elapsed: 0:16:02.\n  Batch   720  of  2,171.    Elapsed: 0:16:59.\n  Batch   760  of  2,171.    Elapsed: 0:17:58.\n  Batch   800  of  2,171.    Elapsed: 0:18:55.\n  Batch   840  of  2,171.    Elapsed: 0:19:53.\n  Batch   880  of  2,171.    Elapsed: 0:20:51.\n  Batch   920  of  2,171.    Elapsed: 0:21:49.\n  Batch   960  of  2,171.    Elapsed: 0:22:47.\n  Batch 1,000  of  2,171.    Elapsed: 0:23:42.\n  Batch 1,040  of  2,171.    Elapsed: 0:24:34.\n  Batch 1,080  of  2,171.    Elapsed: 0:25:27.\n  Batch 1,120  of  2,171.    Elapsed: 0:26:21.\n  Batch 1,160  of  2,171.    Elapsed: 0:27:13.\n  Batch 1,200  of  2,171.    Elapsed: 0:28:05.\n  Batch 1,240  of  2,171.    Elapsed: 0:28:58.\n  Batch 1,280  of  2,171.    Elapsed: 0:29:52.\n  Batch 1,320  of  2,171.    Elapsed: 0:30:48.\n  Batch 1,360  of  2,171.    Elapsed: 0:31:47.\n  Batch 1,400  of  2,171.    Elapsed: 0:32:45.\n  Batch 1,440  of  2,171.    Elapsed: 0:33:42.\n  Batch 1,480  of  2,171.    Elapsed: 0:34:39.\n  Batch 1,520  of  2,171.    Elapsed: 0:35:32.\n  Batch 1,560  of  2,171.    Elapsed: 0:36:25.\n  Batch 1,600  of  2,171.    Elapsed: 0:37:18.\n  Batch 1,640  of  2,171.    Elapsed: 0:38:12.\n  Batch 1,680  of  2,171.    Elapsed: 0:39:09.\n  Batch 1,720  of  2,171.    Elapsed: 0:40:07.\n  Batch 1,760  of  2,171.    Elapsed: 0:41:05.\n  Batch 1,800  of  2,171.    Elapsed: 0:42:03.\n  Batch 1,840  of  2,171.    Elapsed: 0:42:56.\n  Batch 1,880  of  2,171.    Elapsed: 0:43:49.\n  Batch 1,920  of  2,171.    Elapsed: 0:44:42.\n  Batch 1,960  of  2,171.    Elapsed: 0:45:36.\n  Batch 2,000  of  2,171.    Elapsed: 0:46:32.\n  Batch 2,040  of  2,171.    Elapsed: 0:47:30.\n  Batch 2,080  of  2,171.    Elapsed: 0:48:28.\n  Batch 2,120  of  2,171.    Elapsed: 0:49:26.\n  Batch 2,160  of  2,171.    Elapsed: 0:50:23.\n\n  Average training loss: 0.05\n  Training epcoh took: 0:50:39\nRunning Validation...\n  Average validation loss: 0.07\nTotal training took 2:47:12 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlflow.start_run()\n",
    "loss_values = []\n",
    "val_loss_vaues=[]\n",
    "total_t0 = time.time()\n",
    "for epoch in range(epochs):\n",
    "  print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
    "  print('Training...')\n",
    "  # Measure how long the training epoch takes.\n",
    "  training_stats = []\n",
    "  model.train()\n",
    "  total_loss = 0\n",
    "  t0 = time.time()\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss, logits = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask, \n",
    "                            labels=b_labels).to_tuple()\n",
    "    total_loss += loss.item()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "  avg_train_loss = total_loss / len(train_dataloader)\n",
    "  loss_values.append(avg_train_loss)\n",
    "  # Measure how long this epoch took.\n",
    "  training_time = format_time(time.time() - t0)\n",
    "  \n",
    "  print(\"\")\n",
    "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "  # print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "  print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "  # Validation\n",
    "  print(\"Running Validation...\")\n",
    "\n",
    "\n",
    "  t0 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "  model.eval()\n",
    "  total_eval_loss = 0\n",
    "  val_predictions = []\n",
    "  for batch in validation_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    with torch.no_grad():\n",
    "      loss, logits = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask,labels=b_labels).to_tuple()\n",
    "    total_eval_loss += loss.item()\n",
    "    predicted_labels = torch.argmax(logits, dim=2)\n",
    "    val_predictions.extend(predicted_labels.detach().cpu().numpy())\n",
    "\n",
    "  avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "  val_loss_vaues.append(avg_val_loss)\n",
    "  validation_time = format_time(time.time() - t0)\n",
    "\n",
    "  print(\"  Average validation loss: {0:.2f}\".format(avg_val_loss))\n",
    "  mlflow.log_param(\"lr\", lr)\n",
    "  mlflow.log_metric(\"epoch\", epoch + 1)\n",
    "  mlflow.log_metric(\"average_train_loss\", avg_train_loss, step=epoch+1)\n",
    "  mlflow.log_metric(\"average_val_loss\", avg_val_loss,step=epoch+1)\n",
    "  \n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a652912-e137-4e09-8034-866c21d2666e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# print('Predicting labels for {:,} test sentences...'.format(len(pt_input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in test_dataloader:\n",
    "  # Add batch to GPU\n",
    "  b_input_ids = batch[0].to(device)\n",
    "  b_input_mask = batch[1].to(device)\n",
    "  b_labels = batch[2].to(device)\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "795eafac-4a17-4666-899f-024ac1729db2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After flattening the batches, the predictions have shape:\n     (6369, 512, 2)\n\nAfter choosing the highest scoring label for each token:\n     (6369, 512)\n\nAfter flattening the sentences, we have predictions:\n     (3260928,)\nand ground truth:\n     (3260928,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# First, combine the results across the batches.\n",
    "all_predictions = np.concatenate(predictions, axis=0)\n",
    "all_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "print(\"After flattening the batches, the predictions have shape:\")\n",
    "print(\"    \", all_predictions.shape)\n",
    "\n",
    "# Next, let's remove the third dimension (axis 2), which has the scores\n",
    "# for all 18 labels. \n",
    "\n",
    "# For each token, pick the label with the highest score.\n",
    "predicted_label_ids = np.argmax(all_predictions, axis=2)\n",
    "\n",
    "print(\"\\nAfter choosing the highest scoring label for each token:\")\n",
    "print(\"    \", predicted_label_ids.shape) \n",
    "\n",
    "\n",
    "# Eliminate axis 0, which corresponds to the sentences.\n",
    "predicted_label_ids = np.concatenate(predicted_label_ids, axis=0)\n",
    "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "\n",
    "print(\"\\nAfter flattening the sentences, we have predictions:\")\n",
    "print(\"    \", predicted_label_ids.shape)\n",
    "print(\"and ground truth:\")\n",
    "print(\"    \", all_true_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3294c1e2-234b-4189-9c40-2ce9771f2df6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering out `null` tokens, length = 3,260,928\n After filtering out `null` tokens, length = 146,314\n"
     ]
    }
   ],
   "source": [
    "# Construct new lists of predictions which don't include any null tokens.\n",
    "real_token_predictions = []\n",
    "real_token_labels = []\n",
    "\n",
    "# For each of the input tokens in the dataset...\n",
    "for i in range(len(all_true_labels)):\n",
    "\n",
    "    # If it's not a token with a null label...\n",
    "    if not all_true_labels[i] == -100:\n",
    "        \n",
    "        # Add the prediction and the ground truth to their lists.\n",
    "        real_token_predictions.append(predicted_label_ids[i])\n",
    "        real_token_labels.append(all_true_labels[i])\n",
    "\n",
    "print(\"Before filtering out `null` tokens, length = {:,}\".format(len(all_true_labels)))\n",
    "print(\" After filtering out `null` tokens, length = {:,}\".format(len(real_token_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c5d8f15-8ab8-4ef7-8e69-6083d5537561",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# from seqeval.metrics import classification_report\n",
    "\n",
    "\n",
    "# f1 = f1_score(real_token_labels, real_token_predictions, average='micro')\n",
    "labels = [ids_to_labels[id.item()] for id in real_token_labels]\n",
    "predictions = [ids_to_labels[id.item()] for id in real_token_predictions]\n",
    "\n",
    "# print (\"F1 score: {:.2%}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a418c3e9-d0ca-4abf-af31-21fed67e588c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n\nGene_protein       0.00      0.00      0.00         0\n           O       1.00      0.99      1.00    146314\n\n    accuracy                           0.99    146314\n   macro avg       0.50      0.50      0.50    146314\nweighted avg       1.00      0.99      1.00    146314\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# from seqeval.metrics import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc7de854-df01-4e8b-8dbc-b4032944d6ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(labels, predictions, output_dict=True)\n",
    "\n",
    "df = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e57b8b8-4b55-4ab6-b0da-146957ea5cbb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"/dbfs/FileStore/Chanchal/logs/pubmedbertgene(all)-biored1.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8c01af3-998a-4590-8e6a-1fc872b3e544",
     "showTitle": true,
     "title": "Test on Jnplba"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\nError\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Read the data\n",
    "path=\"/dbfs/FileStore/Chanchal/Data_json/JNPLBA.json\"\n",
    "test_df=read_file(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbb5c52c-6c9a-4b19-bead-e570949af050",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags: 2\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "O               207324\n",
       "Gene_protein     28195\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#addding data to dataframe\n",
    "\n",
    "target_labels = ['protein', 'O']\n",
    "test_df = test_df[test_df['label'].isin(target_labels)]\n",
    "test_df['label'] = test_df['label'].replace(['protein'], 'Gene_protein')\n",
    "print(\"Number of tags: {}\".format(len(test_df.label.unique())))\n",
    "frequencies = test_df.label.value_counts()\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a519eae9-1658-4b43-a1cc-4e71436536d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_n_df=aggr(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69878c88-31ed-49e6-9f11-a99070ba63b8",
     "showTitle": true,
     "title": "Tokenizing the text"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#converting text and labels for test_data\n",
    "\n",
    "lb = [i.split() for i in test_n_df['labels'].values.tolist()]\n",
    "txt = test_n_df['text'].values.tolist()\n",
    "test_new_label=[align_label(i,j) for i,j in zip(txt, lb)]\n",
    "test_input_ids,test_attention_masks=tokenizing(test_n_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dee3bd6-fd07-4cd8-889f-9b2b927bd219",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_pt_input_ids = torch.stack(list(test_input_ids), dim=0)\n",
    "\n",
    "test_pt_attention_masks = torch.stack(list(test_attention_masks), dim=0)\n",
    "\n",
    "test_pt_labels = torch.tensor(test_new_label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f7dbd54-fe98-4056-b029-5ffb57057806",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "test_dataset= TensorDataset(test_pt_input_ids, test_pt_attention_masks, test_pt_labels)\n",
    "\n",
    "test_dataloader=DataLoader(test_dataset, sampler = SequentialSampler(test_dataset), batch_size = batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e68bd1d-8466-419e-b6cf-d0baee8c1cd0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in test_dataloader:\n",
    "  # Add batch to GPU\n",
    "  b_input_ids = batch[0].to(device)\n",
    "  b_input_mask = batch[1].to(device)\n",
    "  b_labels = batch[2].to(device)\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8722661c-8e41-4b83-b7bd-c0d39727072d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After flattening the batches, the predictions have shape:\n     (9987, 512, 2)\n\nAfter choosing the highest scoring label for each token:\n     (9987, 512)\n\nAfter flattening the sentences, we have predictions:\n     (5113344,)\nand ground truth:\n     (5113344,)\n"
     ]
    }
   ],
   "source": [
    "# First, combine the results across the batches.\n",
    "all_predictions = np.concatenate(predictions, axis=0)\n",
    "all_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "print(\"After flattening the batches, the predictions have shape:\")\n",
    "print(\"    \", all_predictions.shape)\n",
    "\n",
    "# Next, let's remove the third dimension (axis 2), which has the scores\n",
    "# for all 18 labels. \n",
    "\n",
    "# For each token, pick the label with the highest score.\n",
    "predicted_label_ids = np.argmax(all_predictions, axis=2)\n",
    "\n",
    "print(\"\\nAfter choosing the highest scoring label for each token:\")\n",
    "print(\"    \", predicted_label_ids.shape) \n",
    "\n",
    "\n",
    "# Eliminate axis 0, which corresponds to the sentences.\n",
    "predicted_label_ids = np.concatenate(predicted_label_ids, axis=0)\n",
    "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "\n",
    "print(\"\\nAfter flattening the sentences, we have predictions:\")\n",
    "print(\"    \", predicted_label_ids.shape)\n",
    "print(\"and ground truth:\")\n",
    "print(\"    \", all_true_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d0cc515-b21b-4985-aabc-2257cf1d12ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering out `null` tokens, length = 5,113,344\n After filtering out `null` tokens, length = 245,075\n"
     ]
    }
   ],
   "source": [
    "# Construct new lists of predictions which don't include any null tokens.\n",
    "real_token_predictions = []\n",
    "real_token_labels = []\n",
    "\n",
    "# For each of the input tokens in the dataset...\n",
    "for i in range(len(all_true_labels)):\n",
    "\n",
    "    # If it's not a token with a null label...\n",
    "    if not all_true_labels[i] == -100:\n",
    "        \n",
    "        # Add the prediction and the ground truth to their lists.\n",
    "        real_token_predictions.append(predicted_label_ids[i])\n",
    "        real_token_labels.append(all_true_labels[i])\n",
    "\n",
    "print(\"Before filtering out `null` tokens, length = {:,}\".format(len(all_true_labels)))\n",
    "print(\" After filtering out `null` tokens, length = {:,}\".format(len(real_token_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca48eb30-478e-41a2-8c48-1ce86c3549de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "labels = [ids_to_labels[id.item()] for id in real_token_labels]\n",
    "predictions = [ids_to_labels[id.item()] for id in real_token_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f87aec4-e004-4296-82dd-b5d6b034b662",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n\nGene_protein       0.86      0.92      0.89     30752\n           O       0.99      0.98      0.98    214323\n\n    accuracy                           0.97    245075\n   macro avg       0.92      0.95      0.94    245075\nweighted avg       0.97      0.97      0.97    245075\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c14b49e1-8b3c-46fe-a8ed-fe4cb23e7367",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "report = classification_report(labels, predictions, output_dict=True)\n",
    "\n",
    "df2 = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40ca596a-ee38-45dd-a189-a8a5d724124b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2.to_csv(\"/dbfs/FileStore/Chanchal/logs/pubmedbertgene(all)--jnplba1.csv\", index = True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "gene_pubmed_implementation_(biored+europe+jnplba--biored,europe,jnplba",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
